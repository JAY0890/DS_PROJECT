{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210b679-61af-4688-b303-17d3790cd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 1. author\n",
    "print(df['author'].nunique(), \"unique authors\")\n",
    "top_authors = df['author'].value_counts().head(10)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=top_authors.values, y=top_authors.index)\n",
    "plt.title(\"Top 10 Authors by Article Count\")\n",
    "plt.show()\n",
    "\n",
    "# 2. published (date distribution)\n",
    "df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "plt.figure(figsize=(12,5))\n",
    "df['published'].dt.date.value_counts().sort_index().plot()\n",
    "plt.title(\"Articles Published Over Time\")\n",
    "plt.show()\n",
    "\n",
    "# 3. title (length distribution)\n",
    "df['title_len'] = df['title'].astype(str).apply(len)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['title_len'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Title Lengths\")\n",
    "plt.show()\n",
    "\n",
    "# 4. text (length distribution)\n",
    "df['text_len'] = df['text'].astype(str).apply(len)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['text_len'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Text Lengths\")\n",
    "plt.show()\n",
    "\n",
    "# 5. language\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df['language'])\n",
    "plt.title(\"Distribution of Languages\")\n",
    "plt.show()\n",
    "\n",
    "# 6. site_url (top 10 sites)\n",
    "top_sites = df['site_url'].value_counts().head(10)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=top_sites.values, y=top_sites.index)\n",
    "plt.title(\"Top 10 Site URLs by Article Count\")\n",
    "plt.show()\n",
    "\n",
    "# 7. main_img_url (has image vs not)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df['hasImage'])\n",
    "plt.title(\"Articles with/without Images\")\n",
    "plt.show()\n",
    "\n",
    "# 8. type\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df['type'])\n",
    "plt.title(\"Distribution of News Type\")\n",
    "plt.show()\n",
    "\n",
    "# 9. label\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df['label'])\n",
    "plt.title(\"Distribution of Labels (Fake/Real)\")\n",
    "plt.show()\n",
    "\n",
    "# 10. hasImage already covered above\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f75de4-874a-41ac-a645-0ff9069dc373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Check null values\\nprint(df.isnull().sum())\\n\\n# Drop duplicates if any\\ndf.drop_duplicates(inplace=True)\\n\\ndf = df.dropna(subset=['text', 'label'])\\ndf = df.drop(columns=['title_without_stopwords', 'text_without_stopwords'], errors='ignore')\\n\\ndf['label'] = df['label'].map({'Real': True, 'Fake': False})\\n\\n# Convert 'published' safely with UTC handling\\ndf['published'] = pd.to_datetime(df['published'], errors='coerce', utc=True)\\n\\n# Drop rows where parsing failed (NaT values)\\ndf = df.dropna(subset=['published'])\\n\\n# Extract just the date (no timezone)\\ndf['pub_date'] = df['published'].dt.date\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Check null values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop duplicates if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df = df.drop(columns=['title_without_stopwords', 'text_without_stopwords'], errors='ignore')\n",
    "\n",
    "df['label'] = df['label'].map({'Real': True, 'Fake': False})\n",
    "\n",
    "# Convert 'published' safely with UTC handling\n",
    "df['published'] = pd.to_datetime(df['published'], errors='coerce', utc=True)\n",
    "\n",
    "# Drop rows where parsing failed (NaT values)\n",
    "df = df.dropna(subset=['published'])\n",
    "\n",
    "# Extract just the date (no timezone)\n",
    "df['pub_date'] = df['published'].dt.date\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefce7e9-9a8b-4cf8-b288-8ffa5918cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(\"After drop_duplicates:\", df.shape)\n",
    "\n",
    "# Drop unnecessary columns if present\n",
    "df = df.drop(columns=['title_without_stopwords', 'text_without_stopwords'], errors='ignore')\n",
    "\n",
    "# Check label values BEFORE filtering\n",
    "print(\"Unique labels before cleaning:\", df['label'].unique())\n",
    "\n",
    "# Remove rows where text or label is missing\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "print(\"After dropna on text & label:\", df.shape)\n",
    "\n",
    "# Keep only valid labels\n",
    "valid_labels = ['Real', 'Fake']\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "print(\"After keeping valid labels:\", df.shape)\n",
    "\n",
    "# Map labels to boolean\n",
    "df['label'] = df['label'].map({'Real': True, 'Fake': False})\n",
    "\n",
    "# Convert published to datetime (UTC)\n",
    "#df['published'] = pd.to_datetime(df['published'], errors='coerce', utc=True)\n",
    "\n",
    "# Drop rows where published could not be parsed\n",
    "print(\"NaT count in published:\", df['published'].isna().sum())\n",
    "df = df.dropna(subset=['published'])\n",
    "print(\"After dropping invalid published:\", df.shape)\n",
    "\n",
    "# Extract date only\n",
    "df['pub_date'] = pd.to_datetime(df['published'].dt.date)\n",
    "\n",
    "# Convert author to pandas string type\n",
    "df['author'] = df['author'].astype(\"string\")\n",
    "\n",
    "# Convert text-heavy fields to string\n",
    "df['title'] = df['title'].astype(\"string\")\n",
    "df['text'] = df['text'].astype(\"string\")\n",
    "df['site_url'] = df['site_url'].astype(\"string\")\n",
    "df['main_img_url'] = df['main_img_url'].astype(\"string\")\n",
    "\n",
    "# Convert categorical fields\n",
    "df['language'] = df['language'].astype(\"category\")\n",
    "df['type'] = df['type'].astype(\"category\")\n",
    "\n",
    "# Convert hasImage to int\n",
    "df['hasImage'] = df['hasImage'].fillna(0).astype(int)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"Final shape:\", df.shape)\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
